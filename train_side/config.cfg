[general]
seq_length   = 40
skip        = 1
image_size = (56,32)
batch_size  = 64
n_epochs      = 40
steps_per_epoch = 5
nb_classes  = 9
n_videos = {'train': None, 'validation': None}
labels_want = ['Swiping Left', 'Swiping Right', 'Thumb Down', 'Thumb Up', 'Drumming Fingers','Stop Sign', 'Zooming In With Two Fingers', 'Zooming Out With Two Fingers', 'No gesture', 'Doing other things']
#Choose the mode between {train, test}
mode = train

[path]
#Name used for the folder where the weights and graphs will be saved
model_name = 3D_CONV
#Root folder containing the data
data_root  = D:\project\dataset\jester
#Folder name that will contain the models
data_model = models
#Folder name that contains the dataset of videos
data_vid   = 20bn-jester-v1

#Absolute path to a weight file to load (set to None if you want to start from scratch) 
path_weights = None

#Path to each csv needed (from data_root)
csv_labels = D:\project\dataset\jester\labels.csv
csv_train  = D:\project\dataset\jester\train.csv
csv_val    = D:\project\dataset\jester\validation.csv
csv_test   = D:\project\dataset\jester\test.csv

[option]
workers = 4
use_multiprocessing = True
max_queue_size = 20